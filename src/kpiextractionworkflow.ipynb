{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rJ6pBuw0AQ5"
      },
      "source": [
        "# KPI Extraction Workflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install openai\n",
        "# !pip install langchain\n",
        "# !pip install langgraph\n",
        "# !pip install langchain-community\n",
        "# !pip install -qU langchain-openai\n",
        "# !pip install streamlit\n",
        "# !pip install tiktoken\n",
        "# !pip install sqlparse\n",
        "# !pip install sqlglot black\n",
        "# !pip install sqlfluff\n",
        "# !pip install matplotlib\n",
        "# !pip install pip-system-certs\n",
        "# !pip install -qU pypdf\n",
        "# !pip install PyMuPDF\n",
        "# !pip install easyocr\n",
        "# !pip install fitz"
      ],
      "metadata": {
        "id": "Q26zzC7W0Mdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "H365Y_UYEcBO",
        "outputId": "21cc2f82-3675-4ea0-af5c-9e1d40467b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tesseract\n",
            "  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562552 sha256=ba868731da2f24ab139fc77a88c5befafd3cef87be305d0427c7615682353f05\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/47/6e/bb7543eee5b12cf0bbeedd33b40886429a79aef0b03d76e051\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import openai\n",
        "import pytesseract\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "from langchain import OpenAI\n",
        "from langgraph.graph import StateGraph, State\n",
        "\n",
        "# ----------- CONFIGURATION ----------- #\n",
        "MAX_API_RETRIES = 2\n",
        "MISTRAL_API_URL = \"https://api.mistral.com/ocr\"\n",
        "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
        "TESSERACT_CMD = r'/usr/local/bin/tesseract'  # Update as per your system\n",
        "pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD\n",
        "\n",
        "KPIS = [\n",
        "    \"LP Contribution\", \"GP Contribution\", \"LP Distribution\", \"GP Distribution\",\n",
        "    \"Net IRR\", \"Net Interest\", \"LP NAV\", \"GP NAV\", \"Net Debt\"\n",
        "]\n",
        "\n",
        "# ----------- UTILITIES ----------- #\n",
        "def extract_text_local(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "            # OCR for images\n",
        "            pix = page.get_pixmap()\n",
        "            text += pytesseract.image_to_string(pix.tobytes())\n",
        "    return text\n",
        "\n",
        "def extract_text_api(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        for attempt in range(MAX_API_RETRIES):\n",
        "            try:\n",
        "                response = openai.Completion.create(\n",
        "                    api_key=MISTRAL_API_KEY,\n",
        "                    engine=\"text-davinci-003\",\n",
        "                    prompt=\"Extract text from the uploaded PDF.\",\n",
        "                    files=[file]\n",
        "                )\n",
        "                return response.text\n",
        "            except Exception as e:\n",
        "                if attempt == MAX_API_RETRIES - 1:\n",
        "                    print(f\"API Error: {e}. Skipping file.\")\n",
        "                else:\n",
        "                    time.sleep(2)\n",
        "    return \"\"\n",
        "\n",
        "def convert_to_markdown(text):\n",
        "    # Basic markdown conversion; enhance as needed\n",
        "    return f\"```markdown\\n{text}\\n```\"\n",
        "\n",
        "def extract_kpis(markdown_text, llm):\n",
        "    prompt = (\n",
        "        f\"Extract the following KPIs from the text:\\n\"\n",
        "        f\"{', '.join(KPIS)}\\n\"\n",
        "        f\"Text:\\n{markdown_text}\\n\"\n",
        "        \"Return as a JSON object.\"\n",
        "    )\n",
        "    response = llm(prompt)\n",
        "    return response\n",
        "\n",
        "def save_to_excel(file_name, kpis):\n",
        "    df = pd.DataFrame([kpis])\n",
        "    df.to_excel(f\"{file_name}.xlsx\", index=False)\n",
        "\n",
        "# ----------- STATE MANAGEMENT ----------- #\n",
        "class KPIsState(State):\n",
        "    files: dict\n",
        "\n",
        "# ----------- LANGGRAPH NODES ----------- #\n",
        "def start_node(state: KPIsState):\n",
        "    return state\n",
        "\n",
        "def text_extraction_node(state: KPIsState):\n",
        "    for file, data in state.files.items():\n",
        "        if not data['text_extracted']:\n",
        "            text = extract_text_local(file)\n",
        "            if not text:\n",
        "                text = extract_text_api(file)\n",
        "            state.files[file]['markdown'] = convert_to_markdown(text)\n",
        "            state.files[file]['text_extracted'] = True\n",
        "    return state\n",
        "\n",
        "def kpi_extraction_node(state: KPIsState):\n",
        "    llm = OpenAI(temperature=0)\n",
        "    for file, data in state.files.items():\n",
        "        if not data['kpis_extracted']:\n",
        "            result = extract_kpis(data['markdown'], llm)\n",
        "            missing_kpis = [kpi for kpi in KPIS if not result.get(kpi)]\n",
        "            if missing_kpis and data['retry_count'] == 0:\n",
        "                data['retry_count'] += 1\n",
        "                data['text_extracted'] = False  # Trigger DeepOCR\n",
        "            else:\n",
        "                data['kpis'] = result\n",
        "                data['kpis_extracted'] = True\n",
        "    return state\n",
        "\n",
        "def save_results_node(state: KPIsState):\n",
        "    for file, data in state.files.items():\n",
        "        save_to_excel(file, data['kpis'])\n",
        "    return state\n",
        "\n",
        "def end_node(state: KPIsState):\n",
        "    print(\"Workflow completed.\")\n",
        "    return state\n",
        "\n",
        "# ----------- WORKFLOW SETUP ----------- #\n",
        "graph = StateGraph()\n",
        "\n",
        "graph.add_node(\"start\", start_node)\n",
        "graph.add_node(\"extract_text\", text_extraction_node)\n",
        "graph.add_node(\"extract_kpis\", kpi_extraction_node)\n",
        "graph.add_node(\"save_results\", save_results_node)\n",
        "graph.add_node(\"end\", end_node)\n",
        "\n",
        "graph.connect(\"start\", \"extract_text\")\n",
        "graph.connect(\"extract_text\", \"extract_kpis\")\n",
        "graph.connect(\"extract_kpis\", \"extract_text\")  # Loop back if retries needed\n",
        "graph.connect(\"extract_kpis\", \"save_results\")\n",
        "graph.connect(\"save_results\", \"end\")\n",
        "\n",
        "graph.compile()\n",
        "\n",
        "def run_workflow(files):\n",
        "    initial_state = KPIsState(files={file: {\n",
        "        'text_extracted': False,\n",
        "        'kpis_extracted': False,\n",
        "        'retry_count': 0,\n",
        "        'kpis': {}\n",
        "    } for file in files})\n",
        "\n",
        "    graph.run(initial_state)\n",
        "\n",
        "# Example Usage:\n",
        "# run_workflow(['filea.pdf', 'fileb.pdf'])\n"
      ],
      "metadata": {
        "id": "_FfaZ3gc07oI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}