{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "fIvQCr8oR2sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --quiet -U langchain_openai langchain_core langchain_community langgraph"
      ],
      "metadata": {
        "id": "UjhMCY19R8a4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "from pprint import pprint\n",
        "from google.colab import userdata\n",
        "from IPython.display import display, Image\n",
        "from operator import add\n",
        "from typing import List, Literal, Annotated, Optional\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, field_validator, ValidationError, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, AnyMessage, SystemMessage, ToolMessage, RemoveMessage\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.checkpoint.memory import MemorySaver"
      ],
      "metadata": {
        "id": "kd876CJdTJ4K"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GIRU_OPENAI_API_KEY = userdata.get('GIRU_OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = GIRU_OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "fcjiU_E5TD-R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking openai llm\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "result = llm.invoke(\"Hi, are you deepseek?\")\n",
        "\n",
        "# printing results\n",
        "print(\"===\"*25)\n",
        "print(f\"RESPONSE\\n{result.content}\")\n",
        "print(\"===\"*25)\n",
        "print(\"METADATA\")\n",
        "print(f\"model: {result.response_metadata['model_name']}\")\n",
        "for k, v in result.response_metadata['token_usage'].items():\n",
        "  print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNUO-rd3S9p8",
        "outputId": "68d5166f-aa20-456d-b781-98f2df8aef34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================================================\n",
            "RESPONSE\n",
            "No, I'm not DeepSeek. I'm an AI language model created by OpenAI. How can I assist you today?\n",
            "===========================================================================\n",
            "METADATA\n",
            "model: gpt-4o-mini-2024-07-18\n",
            "completion_tokens: 25\n",
            "prompt_tokens: 14\n",
            "total_tokens: 39\n",
            "completion_tokens_details: {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}\n",
            "prompt_tokens_details: {'audio_tokens': 0, 'cached_tokens': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KPIDetail(BaseModel):\n",
        "    name: str = Field(..., description=\"Exact name of the KPI\")\n",
        "    description: str = Field(..., description=\"Detailed explanation of what the KPI measures\")\n",
        "    value: Optional[str] = Field(default=\"Not specified\", description=\"Extracted numeric or textual value of the KPI\")\n",
        "    confidence_score: float = Field(default=0.0, description=\"Confidence of extraction (0.0-1.0)\")\n",
        "    source_context: Optional[str] = Field(default=None, description=\"Contextual snippet supporting the KPI extraction\")"
      ],
      "metadata": {
        "id": "IyrvTW-sUAiV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KPIExtraction(BaseModel):\n",
        "    kpis: List[KPIDetail] = Field(..., description=\"List of extracted KPIs\")\n",
        "    extraction_notes: Optional[str] = Field(default=None, description=\"Additional notes about the extraction process\")"
      ],
      "metadata": {
        "id": "_N9CLIBvU0dH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt for KPI extraction\n",
        "kpi_extraction_prompt = PromptTemplate(\n",
        "    input_variables=[\"document_text\", \"target_kpis\", \"parser\"],\n",
        "    template=\"\"\"🔍 Advanced KPI Extraction Protocol 🔍\n",
        "\n",
        "Objective: Perform a comprehensive, precise extraction of Key Performance Indicators from the provided document.\n",
        "\n",
        "Extraction Criteria:\n",
        "1. Target KPIs to Extract:\n",
        "\\\"\\\"\\\"\n",
        "{target_kpis}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Extraction Guidelines:\n",
        "- Mandatory Inclusion: Every target KPI MUST be addressed, even if not directly found\n",
        "- Exhaustive Search: Scan the entire document thoroughly\n",
        "- Contextual Awareness: Provide surrounding context for extracted values\n",
        "- Confidence Assessment: Rate the reliability of each extraction\n",
        "\n",
        "Detailed Extraction Requirements:\n",
        "✅ KPI Name: Exact, verbatim name\n",
        "✅ Description: Comprehensive explanation of the KPI's significance\n",
        "✅ Value:\n",
        "   - Precise numeric or textual representation\n",
        "   - Use \"Not specified\" if no clear value is found\n",
        "   - Include units of measurement if present\n",
        "✅ Confidence Score:\n",
        "   - 1.0: Extremely confident (direct, unambiguous extraction)\n",
        "   - 0.7-0.9: High confidence (strong contextual evidence)\n",
        "   - 0.4-0.6: Moderate confidence (partial or inferential evidence)\n",
        "   - 0.1-0.3: Low confidence (weak or speculative extraction)\n",
        "   - 0.0: No evidence found\n",
        "✅ Source Context: Brief text snippet supporting the extraction\n",
        "\n",
        "Prohibited Actions:\n",
        "❌ Do NOT fabricate or invent KPI values\n",
        "❌ Do NOT omit any target KPI from the response\n",
        "❌ Avoid generic or vague descriptions\n",
        "\n",
        "Response Format Mandate:\n",
        "{parser}\n",
        "\n",
        "Source Document:\n",
        "\\\"\\\"\\\"\n",
        "{document_text}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Special Instructions:\n",
        "- If a KPI requires complex interpretation, explain your reasoning\n",
        "- Highlight any unusual or noteworthy observations\n",
        "- Be academically rigorous and precise\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "RqmUg2lvVVOq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the schema for state data\n",
        "class KPIState(State):\n",
        "    file_path: str\n",
        "    extracted_text: str = \"\"\n",
        "    kpi_data: Dict[str, Any] = {}\n",
        "    validated_data: Dict[str, Any] = {}\n",
        "\n",
        "# Node 1: Loader Node\n",
        "def load_pdf_node(state: KPIState) -> KPIState:\n",
        "    from PyPDF2 import PdfReader\n",
        "    reader = PdfReader(state.file_path)\n",
        "    text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "    state.extracted_text = text\n",
        "    return state\n",
        "\n",
        "# Node 2: Extractor Node\n",
        "def extractor_node(state: KPIState) -> KPIState:\n",
        "    if state.extracted_text.strip():\n",
        "        return state\n",
        "    else:\n",
        "        import pytesseract\n",
        "        from PIL import Image\n",
        "        text = pytesseract.image_to_string(Image.open(state.file_path))\n",
        "        state.extracted_text = text\n",
        "        return state\n",
        "\n",
        "# Node 3: KPI Extractor Node\n",
        "def kpi_extractor_node(state: KPIState) -> KPIState:\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "    prompt = f\"\"\"\n",
        "    Extract the following KPIs from the provided text:\n",
        "    - LP Contribution\n",
        "    - GP Contribution\n",
        "    - LP Distribution\n",
        "    - GP Distribution\n",
        "    - Net IRR\n",
        "    - Net Interest\n",
        "    - LP NAV\n",
        "    - GP NAV\n",
        "    - Net Debt\n",
        "\n",
        "    Format as JSON.\n",
        "\n",
        "    Text:\n",
        "    {state.extracted_text}\n",
        "    \"\"\"\n",
        "    response = llm.predict(prompt)\n",
        "    state.kpi_data = response\n",
        "    return state\n",
        "\n",
        "# Node 4: Human Validation Node\n",
        "def human_validation_node(state: KPIState) -> KPIState:\n",
        "    print(\"Extracted KPIs:\", state.kpi_data)\n",
        "    decision = input(\"Accept or Reject? (a/r): \")\n",
        "    if decision.lower() == 'a':\n",
        "        state.validated_data = state.kpi_data\n",
        "    else:\n",
        "        feedback = input(\"Enter your feedback or corrections: \")\n",
        "        state.kpi_data = kpi_extractor_node(KPIState(file_path=state.file_path, extracted_text=feedback)).kpi_data\n",
        "        state.validated_data = state.kpi_data\n",
        "    return state\n",
        "\n",
        "# Node 5: Save to Excel Node\n",
        "def save_excel_node(state: KPIState) -> KPIState:\n",
        "    df = pd.DataFrame([state.validated_data])\n",
        "    output_file = os.path.splitext(state.file_path)[0] + \"_output.xlsx\"\n",
        "    df.to_excel(output_file, index=False)\n",
        "    return state\n",
        "\n",
        "# Define the LangGraph workflow\n",
        "graph = StateGraph(schema=KPIState)\n",
        "graph.add_node(\"loader\", load_pdf_node)\n",
        "graph.add_node(\"extractor\", extractor_node)\n",
        "graph.add_node(\"kpi_extractor\", kpi_extractor_node)\n",
        "graph.add_node(\"human_validation\", human_validation_node)\n",
        "graph.add_node(\"save_excel\", save_excel_node)\n",
        "\n",
        "graph.set_entry_point(\"loader\")\n",
        "graph.connect(\"loader\", \"extractor\")\n",
        "graph.connect(\"extractor\", \"kpi_extractor\")\n",
        "graph.connect(\"kpi_extractor\", \"human_validation\")\n",
        "graph.connect(\"human_validation\", \"save_excel\")\n",
        "graph.set_exit_point(\"save_excel\")\n",
        "\n",
        "# Run the workflow\n",
        "def run_workflow(file_path: str):\n",
        "    initial_state = KPIState(file_path=file_path)\n",
        "    graph.run(initial_state)\n",
        "\n",
        "# Example usage\n",
        "# run_workflow(\"sample.pdf\")\n"
      ],
      "metadata": {
        "id": "eAm6WmKvR2ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PBfiLoj_Y16J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GlzSe0zYY13k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Libraries"
      ],
      "metadata": {
        "id": "wbl5kHWzZ50Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pytesseract pdf2image\n",
        "# !pip install pillow pandas openpyxl\n",
        "# !pip install tesseract\n",
        "# !apt-get install -y tesseract-ocr"
      ],
      "metadata": {
        "id": "46KnxXfeY102"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "tazNQmyjZzUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from IPython.display import display, Image\n",
        "from typing import Dict, List, Any\n",
        "from typing_extensions import TypedDict, Annotated, Union\n",
        "\n",
        "# PDF processing libraries\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# LangChain and LangGraph\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.schema import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.schema.runnable import RunnableConfig\n",
        "\n",
        "import langgraph\n",
        "from langgraph.graph import StateGraph, END"
      ],
      "metadata": {
        "id": "3zs1Xq0LZxqI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KPIData(TypedDict):\n",
        "    lp_contribution: str\n",
        "    gp_contribution: str\n",
        "    lp_distribution: str\n",
        "    gp_distribution: str\n",
        "    net_irr: str\n",
        "    net_interest: str\n",
        "    lp_nav: str\n",
        "    gp_nav: str\n",
        "    net_debt: str"
      ],
      "metadata": {
        "id": "QgnHx8obZxnM"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WorkflowState(TypedDict):\n",
        "    file_path: str\n",
        "    extracted_text: str\n",
        "    kpi_data: KPIData\n",
        "    human_feedback: str\n",
        "    status: str\n",
        "    error: str"
      ],
      "metadata": {
        "id": "SocjaauCY1yE"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "j3tUUjPCajer"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf(state: WorkflowState) -> WorkflowState:\n",
        "    \"\"\"Load PDF document from the provided file path.\"\"\"\n",
        "    try:\n",
        "        file_path = state.get(\"file_path\")\n",
        "        if not file_path:\n",
        "            return {**state, \"error\": \"No file path provided\", \"status\": \"error\"}\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            return {**state, \"error\": f\"File not found: {file_path}\", \"status\": \"error\"}\n",
        "\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        docs = loader.load()\n",
        "\n",
        "        # Basic extraction without OCR\n",
        "        basic_text = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        print(f\"✅ Loaded PDF: {file_path}\")\n",
        "\n",
        "        return {**state, \"extracted_text\": basic_text, \"status\": \"pdf_loaded\"}\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": f\"Error loading PDF: {str(e)}\", \"status\": \"error\"}"
      ],
      "metadata": {
        "id": "FVHCwf6KanGr"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf_text(state: WorkflowState) -> WorkflowState:\n",
        "    \"\"\"Extract text from PDF using both regular extraction and OCR.\"\"\"\n",
        "    try:\n",
        "        file_path = state.get(\"file_path\")\n",
        "        basic_text = state.get(\"extracted_text\", \"\")\n",
        "\n",
        "        # Use OCR for images in PDF\n",
        "        images = convert_from_path(file_path)\n",
        "        ocr_text = \"\"\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            # Perform OCR\n",
        "            text = pytesseract.image_to_string(image)\n",
        "            ocr_text += f\"\\n--- Page {i+1} OCR ---\\n{text}\"\n",
        "\n",
        "        # Combine both extraction methods\n",
        "        combined_text = f\"{basic_text}\\n\\n{ocr_text}\"\n",
        "\n",
        "        print(f\"✅ Extracted text from PDF (Regular + OCR)\")\n",
        "\n",
        "        return {**state, \"extracted_text\": combined_text, \"status\": \"text_extracted\"}\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": f\"Error extracting text: {str(e)}\", \"status\": \"error\"}"
      ],
      "metadata": {
        "id": "M9MMZam-bLD_"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_kpis(state: WorkflowState) -> WorkflowState:\n",
        "    \"\"\"Extract KPIs considering human feedback.\"\"\"\n",
        "    try:\n",
        "        text_content = state.get(\"extracted_text\", \"\")\n",
        "        human_feedback = state.get(\"human_feedback\", \"\")\n",
        "\n",
        "        # prompt with human feedback\n",
        "        prompt = f\"\"\"\n",
        "        You are a financial document analysis expert. Extract the following KPIs from the provided text content.\n",
        "        If a value is not found, mark it as 'Not Found'.\n",
        "\n",
        "        Text content from PDF:\n",
        "        ```\n",
        "        {text_content}  # Limiting text length for model context\n",
        "        ```\n",
        "\n",
        "        Extract the following KPIs:\n",
        "        1. LP Contribution\n",
        "        2. GP Contribution\n",
        "        3. LP Distribution\n",
        "        4. GP Distribution\n",
        "        5. Net IRR\n",
        "        6. Net Interest\n",
        "        7. LP NAV\n",
        "        8. GP NAV\n",
        "        9. Net Debt\n",
        "\n",
        "        IMPORTANT HUMAN FEEDBACK TO CONSIDER:\n",
        "        {human_feedback}\n",
        "\n",
        "        Return your findings as a JSON object with these keys:\n",
        "        lp_contribution, gp_contribution, lp_distribution, gp_distribution, net_irr, net_interest, lp_nav, gp_nav, net_debt\n",
        "        \"\"\"\n",
        "\n",
        "        # Extract KPIs using LLM\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "        # Try to parse the JSON from the response\n",
        "        try:\n",
        "            # Look for JSON in the response\n",
        "            response_text = response.content\n",
        "\n",
        "            # Extract JSON part if embedded in text explanation\n",
        "            json_match = re.search(r'```json\\n(.*?)\\n```', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group(1)\n",
        "            else:\n",
        "                # Try to find JSON-like structure\n",
        "                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "                if json_match:\n",
        "                    json_str = json_match.group(0)\n",
        "                else:\n",
        "                    json_str = response_text\n",
        "\n",
        "            kpi_data = json.loads(json_str)\n",
        "\n",
        "            # Ensure all required keys are present\n",
        "            required_keys = [\"lp_contribution\", \"gp_contribution\", \"lp_distribution\", \"gp_distribution\",\n",
        "                            \"net_irr\", \"net_interest\", \"lp_nav\", \"gp_nav\", \"net_debt\"]\n",
        "\n",
        "            for key in required_keys:\n",
        "                if key not in kpi_data:\n",
        "                    kpi_data[key] = \"Not Found\"\n",
        "\n",
        "        except Exception as parse_error:\n",
        "            print(f\"Error parsing LLM response: {str(parse_error)}\")\n",
        "            print(f\"Raw response: {response.content}\")\n",
        "\n",
        "            # Use previous KPI data if parsing fails\n",
        "            kpi_data = state.get(\"kpi_data\", {})\n",
        "\n",
        "        print(f\"✅ Re-extracted KPIs with human feedback\")\n",
        "\n",
        "        return {**state, \"kpi_data\": kpi_data, \"status\": \"kpis_reextracted\"}\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": f\"Error re-extracting KPIs: {str(e)}\", \"status\": \"error\"}"
      ],
      "metadata": {
        "id": "Z5JsYhH0dAF0"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def human_validation(state: WorkflowState) -> Union[str, Dict]:\n",
        "    \"\"\"Present extracted KPIs to human for validation.\"\"\"\n",
        "    try:\n",
        "        kpi_data = state.get(\"kpi_data\", {})\n",
        "\n",
        "        # Format KPI data for display\n",
        "        kpi_display = \"\\n\".join([f\"{k.upper()}: {v}\" for k, v in kpi_data.items()])\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"EXTRACTED KPIs FOR VALIDATION:\")\n",
        "        print(kpi_display)\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Get human feedback\n",
        "        choice = input(\"\\nAccept these KPIs? (yes/no): \").strip().lower()\n",
        "\n",
        "        if choice == \"yes\":\n",
        "            print(\"✅ KPIs accepted!\")\n",
        "            return \"save_to_excel\"\n",
        "        else:\n",
        "            feedback = input(\"Please provide feedback for improving extraction: \")\n",
        "            return {\"feedback\": feedback}\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": f\"Error during human validation: {str(e)}\", \"status\": \"error\"}"
      ],
      "metadata": {
        "id": "LyLOjbGscbD6"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_human_feedback(state: WorkflowState, feedback_data: Dict) -> WorkflowState:\n",
        "    \"\"\"Process human feedback and update state.\"\"\"\n",
        "    feedback = feedback_data.get(\"feedback\", \"\")\n",
        "\n",
        "    # Update state with feedback\n",
        "    updated_state = {\n",
        "        **state,\n",
        "        \"human_feedback\": feedback,\n",
        "        \"status\": \"feedback_received\"\n",
        "    }\n",
        "\n",
        "    print(f\"✅ Human feedback recorded: {feedback}\")\n",
        "\n",
        "    return updated_state"
      ],
      "metadata": {
        "id": "EDYQkWxockYP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_excel(state: WorkflowState) -> WorkflowState:\n",
        "    \"\"\"Save extracted KPIs to Excel file.\"\"\"\n",
        "    try:\n",
        "        kpi_data = state.get(\"kpi_data\", {})\n",
        "        file_path = state.get(\"file_path\", \"unknown\")\n",
        "\n",
        "        # Create filename based on input PDF name\n",
        "        base_name = os.path.basename(file_path)\n",
        "        pdf_name = os.path.splitext(base_name)[0]\n",
        "        excel_path = f\"{pdf_name}_KPIs.xlsx\"\n",
        "\n",
        "        # Convert KPI data to DataFrame\n",
        "        df = pd.DataFrame([kpi_data])\n",
        "\n",
        "        # Save to Excel\n",
        "        df.to_excel(excel_path, index=False)\n",
        "\n",
        "        print(f\"✅ Saved KPIs to Excel: {excel_path}\")\n",
        "\n",
        "        return {**state, \"status\": \"completed\", \"excel_path\": excel_path}\n",
        "    except Exception as e:\n",
        "        return {**state, \"error\": f\"Error saving to Excel: {str(e)}\", \"status\": \"error\"}"
      ],
      "metadata": {
        "id": "8ap8Rly2czw8"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_workflow() -> StateGraph:\n",
        "    # Initialize the graph\n",
        "    workflow = StateGraph(WorkflowState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"load_pdf\", load_pdf)\n",
        "    workflow.add_node(\"extract_pdf_text\", extract_pdf_text)\n",
        "    workflow.add_node(\"extract_kpis\", extract_kpis)\n",
        "    workflow.add_node(\"human_validation\", human_validation)\n",
        "    workflow.add_node(\"process_human_feedback\", process_human_feedback)\n",
        "    workflow.add_node(\"save_to_excel\", save_to_excel)\n",
        "\n",
        "    # Define edges for sequential flow\n",
        "    workflow.add_edge(\"load_pdf\", \"extract_pdf_text\")\n",
        "    workflow.add_edge(\"extract_pdf_text\", \"extract_kpis\")\n",
        "    workflow.add_edge(\"extract_kpis\", \"human_validation\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"human_validation\",\n",
        "        {\n",
        "            \"save_to_excel\": lambda x: x == \"save_to_excel\",\n",
        "            \"process_human_feedback\": lambda x: isinstance(x, dict) and \"feedback\" in x\n",
        "        }\n",
        "    )\n",
        "    workflow.add_edge(\"process_human_feedback\", \"extract_kpis\")\n",
        "    workflow.add_edge(\"extract_kpis\", \"human_validation\")\n",
        "    workflow.add_edge(\"save_to_excel\", END)\n",
        "\n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"load_pdf\")\n",
        "\n",
        "    return workflow"
      ],
      "metadata": {
        "id": "3CUnF84pdv42"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_workflow(pdf_path: str):\n",
        "    workflow = build_workflow()\n",
        "    app = workflow.compile()\n",
        "    # display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
        "    return app"
      ],
      "metadata": {
        "id": "rkJrvxCdfD3A"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_workflow(pdf_path: str):\n",
        "    pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/pytesseract'\n",
        "    app = compile_workflow(pdf_path)\n",
        "\n",
        "    # Initial state\n",
        "    initial_state = WorkflowState(\n",
        "        file_path=pdf_path,\n",
        "        extracted_text=\"\",\n",
        "        kpi_data={},\n",
        "        human_feedback=\"\",\n",
        "        status=\"started\",\n",
        "        error=\"\"\n",
        "    )\n",
        "\n",
        "    # Execute the workflow\n",
        "    for output in app.stream(initial_state):\n",
        "        node = output.get(\"node\")\n",
        "        if node == \"error\":\n",
        "            print(f\"❌ Error: {output['state'].get('error')}\")\n",
        "            return output['state']\n",
        "\n",
        "    # Return the final state\n",
        "    final_state = output.get(\"state\", {})\n",
        "    return final_state"
      ],
      "metadata": {
        "id": "etmbV_upfNcR"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the workflow on the uploaded PDF\n",
        "result = run_workflow(\"/content/sample1.pdf\")\n",
        "\n",
        "# Check the result\n",
        "if result.get(\"status\") == \"completed\":\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"✅ WORKFLOW COMPLETED SUCCESSFULLY\")\n",
        "    print(f\"📊 KPIs saved to: {result.get('excel_path')}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Print extracted KPIs\n",
        "    print(\"\\nExtracted KPIs:\")\n",
        "    kpi_data = result.get(\"kpi_data\", {})\n",
        "    for key, value in kpi_data.items():\n",
        "        print(f\"  - {key.upper()}: {value}\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"❌ WORKFLOW FAILED: {result.get('error')}\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "id": "XLt0wLQeiSTg",
        "outputId": "14b67c86-1691-477b-f846-36b342ec8ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Re-extracted KPIs with human feedback\n",
            "\n",
            "==================================================\n",
            "EXTRACTED KPIs FOR VALIDATION:\n",
            "LP_CONTRIBUTION: Not Found\n",
            "GP_CONTRIBUTION: Not Found\n",
            "LP_DISTRIBUTION: Not Found\n",
            "GP_DISTRIBUTION: Not Found\n",
            "NET_IRR: Not Found\n",
            "NET_INTEREST: Not Found\n",
            "LP_NAV: Not Found\n",
            "GP_NAV: Not Found\n",
            "NET_DEBT: Not Found\n",
            "==================================================\n",
            "\n",
            "Accept these KPIs? (yes/no): no\n",
            "Please provide feedback for improving extraction: Find all the details inside pdf\n",
            "\n",
            "==================================================\n",
            "❌ WORKFLOW FAILED: None\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34EglI-_kv5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}